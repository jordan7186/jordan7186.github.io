<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Presentations | Yong-Min Shin</title> <meta name="author" content="Yong-Min Shin"> <meta name="description" content="These are the selected presentation slides that I have used in internal reading groups, workshops, and conferences."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%94&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jordan7186.github.io/presentations/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Yong-Min Shin</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Graph Learning Blog</a> </li> <li class="nav-item active"> <a class="nav-link" href="/presentations/">Presentations<span class="sr-only">(current)</span></a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Presentations</h1> <p class="post-description">These are the selected presentation slides that I have used in internal reading groups, workshops, and conferences.</p> </header> <article> <h2 id="external-presentations-selected">External Presentations (Selected)</h2> <h4 id="seminar-series-gist">[Seminar series] @GIST</h4> <p>This is a series of seminars that I gave as a guest speaker in Prof. Hong Kook Kim’s group at Gwangju Institute of Science and Technology (GIST) from March ~ May 2025. The seminar series covers the basics of <em>graph learning, graph neural networks, several fundamental concepts, and applications</em>.</p> <p><strong>Session 1:</strong> <a href="/assets/pdf/[GIST]01_Introduction_to_graph_mining_and_graph_neural_networks.pdf">Introduction to graph mining and graph neural networks</a></p> <p><strong>Session 2:</strong> <a href="/assets/pdf/[GIST]02_On_the_representational_power_of_graph_neural_networks.pdf">On the representational power of graph neural networks</a></p> <p><strong>Session 3:</strong> <a href="/assets/pdf/[GIST]03_A_graph_signal_processing_viewpoint_of_graph_neural_networks.pdf">A graph signal processing viewpoint of graph neural networks</a></p> <p><strong>Session 4:</strong> <a href="/assets/pdf/[GIST]04_From_label_propagation_to_graph_neural_networks.pdf">From label propagation to graph neural networks</a></p> <p><strong>Session 5:</strong> <a href="/assets/pdf/[GIST]05_On_the_problem_of_oversmoothing_and_oversquashing.pdf">On the problem of oversmoothing and oversquashing</a></p> <p><strong>Session 6:</strong> <a href="/assets/pdf/[GIST]06_Towards_efficient_graph_learning.pdf">Towards efficient graph learning</a></p> <p><strong>Session 7:</strong> <a href="/assets/pdf/[GIST]07_Explainable_graph_neural_networks.pdf">Explainable graph neural networks</a></p> <h4 id="seminar-ehwa-womans-university">[Seminar] @Ehwa Womans University</h4> <p>This is a seminar that I gave at Ehwa Womans University as a guest lecturer in April 2025.</p> <p><strong>Slides</strong>: <a href="/assets/pdf/Ewha_Uni_lecture.pdf">A practical introduction to (explainable) graph learning</a></p> <h4 id="aaai25-faithful-and-accurate-self-attention-attribution-for-message-passing-neural-networks-via-the-computation-tree-viewpoint">[AAAI’25] Faithful and Accurate Self-Attention Attribution for Message Passing Neural Networks via the Computation Tree Viewpoint</h4> <p>This is the poster for my paper “Faithful and Accurate Self-Attention Attribution for Message Passing Neural Networks via the Computation Tree Viewpoint” that was accepted at AAAI 2025. The arxiv version of the paper can be found <a href="https://arxiv.org/abs/2406.04612" rel="external nofollow noopener" target="_blank">here</a>.</p> <p><strong>Poster:</strong> <a href="/assets/pdf/Poster_final_GAtt.pdf">Faithful and Accurate Self-Attention Attribution for Message Passing Neural Networks via the Computation Tree Viewpoint</a></p> <h4 id="ijcai24-workshop-on-xai-on-the-feasibility-of-fidelity--for-graph-pruning">[IJCAI’24 workshop on XAI] On the Feasibility of Fidelity- for Graph Pruning</h4> <p>This is the poster and presentation slides for my paper “On the Feasibility of Fidelity- for Graph Pruning” presented at the Workshop on Explainable Artificial Intelligence (XAI) at the 2024 International Joint Conference on Artificial Intelligence (IJCAI). The arxiv version of the paper can be found <a href="https://arxiv.org/abs/2406.11504" rel="external nofollow noopener" target="_blank">here</a>.</p> <p><strong>Poster:</strong> <a href="/assets/pdf/Poster_final_IJCAIW2024.pdf">On the Feasibility of Fidelity- for Graph Pruning</a></p> <p><strong>Slide:</strong> <a href="/assets/pdf/240805_IJCAIW_Presentation_Yong-Min_Shin.pdf">On the Feasibility of Fidelity- for Graph Pruning</a></p> <p>And also here is the accompanying blog post: <a href="https://jordan7186.github.io/blog/2024/Fidelity_pruning/">On the Feasibility of Fidelity- for Graph Pruning</a>.</p> <h4 id="best-academic-paper-award-page-prototype-based-model-level-explanations-for-graph-neural-networks">[Best academic paper award] PAGE: Prototype-Based Model-Level Explanations for Graph Neural Networks</h4> <p>This presentation slides were submitted as an official supplementary material after being accepted as the best academic paper at the Graduate School of Yonsei University.</p> <p><strong>Original paper</strong>: Shin et al., “PAGE: Prototype-Based Model-Level Explanations for Graph Neural Networks”, TPAMI (2024)</p> <p><strong>Slide:</strong> <a href="/assets/pdf/Presentation_PAGE.pdf">PAGE: Prototype-Based Model-Level Explanations for Graph Neural Networks</a></p> <p>Also, this is the poster that I presented for the short version, accepted at AAAI 2022.</p> <p><strong>Poster:</strong> <a href="/assets/pdf/Poster_final_AAAI_2022.pdf">PAGE (AAAI 2022)</a></p> <h4 id="samsung-humantech-edgeless-gnn-unsupervised-inductive-edgeless-network-embedding">[Samsung HumanTech] Edgeless-GNN: Unsupervised Inductive Edgeless Network Embedding</h4> <p>This presentation was given during the competition for the 28th Samsung HumanTech Award (<em>Bronze prize</em>).</p> <p><strong>Original paper</strong>: Shin et al,. “Edgeless-GNN: Unsupervised Representation Learning for Edgeless Nodes”, TETC (2022)</p> <p><strong>Slide:</strong> <a href="/assets/pdf/EdgelessGNN_Hutech.pdf">Edgeless-GNN: Unsupervised Inductive Edgeless Network Embedding</a></p> <hr> <h2 id="selected-internal-presentations">Selected Internal Presentations</h2> <p>In my lab, we have a weekly reading group where we present papers of our own interest. Here are some of the selected presentations that I have made in the reading group.</p> <h4 id="topic-causal-learning">Topic: Causal learning</h4> <p>This was a two-part presentation where I introduced the basics of causal learning in an internal seminar at my lab, which I got a LOT of help from <a href="https://www.bradyneal.com/causal-inference-course" rel="external nofollow noopener" target="_blank">“Introduction to Causal Inference” by Brady Neal</a>. Definitely check out his course if you are interested in causal inference, I personally had a lot of fun learning from it.</p> <p><strong>Slide 1:</strong> <a href="/assets/pdf/Causal_learning_part1.pdf">Causal learning: Part 1</a></p> <p><strong>Slide 2:</strong> <a href="/assets/pdf/Causal_learning_part2.pdf">Causal learning: Part 2</a></p> <h4 id="topic-self-supervised-learning">Topic: Self-supervised learning</h4> <p>This was a presentation made when I was interested in understanding the SimCLR framework. Understanding this paper made me understand other papers related in graph self-supervised learning much better.</p> <p><strong>Slide:</strong> <a href="/assets/pdf/SimCLR.pdf">Introduction to SimCLR</a></p> <h4 id="topic-knowledge-distillation">Topic: Knowledge distillation</h4> <p>This was a presentation made when I was interested in understanding knowledge distillation, which I eventually applied to my research on GNN-to-MLP knowledge distillation.</p> <p><strong>Slide:</strong> <a href="/assets/pdf/Knowledge_distillation.pdf">Towards understanding knowledge distillation</a></p> <h4 id="topic-physics-informed-machine-learning-piml">Topic: Physics-informed machine learning (PIML)</h4> <p>This was a presentation made when I was interested in understanding the physics-informed machine learning landscape.</p> <p><strong>Slide:</strong> <a href="/assets/pdf/Vector_Neurons.pdf">Vector Neurons: A General Framework for SO(3)-Equivariant Networks</a></p> <h4 id="topic-unsupervised-disentanglement">Topic: Unsupervised disentanglement</h4> <p>A review of the paper: Challenging common assumptions in the unsupervised learning of disentangled representations by Locatello et al. This paper is a great read if you are interested in disentangled representation learning, and personally, I found it very helpful while reading some papers in explainable AI.</p> <p><strong>Slide:</strong> <a href="/assets/pdf/Unsupervised_disentanglement.pdf">Challenging common assumptions in the unsupervised learning of disentangled representations</a></p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Yong-Min Shin. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>