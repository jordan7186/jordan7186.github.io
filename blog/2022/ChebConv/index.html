<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Understanding ChebConv with the NEIGHBORSMATCH problem | Yong-Min Shin</title> <meta name="author" content="Yong-Min Shin"> <meta name="description" content="Welcome to my homepage! "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%94&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jordan7186.github.io/blog/2022/ChebConv/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Yong-Min Shin</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Understanding ChebConv with the NEIGHBORSMATCH problem</h1> <p class="post-meta">October 30, 2022</p> <p class="post-tags"> <a href="/blog/2022"> <i class="fa-solid fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="/blog/tag/graph-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Graph_learning</a>     ·   <a href="/blog/category/chebconv"> <i class="fa-solid fa-tag fa-sm"></i> ChebConv</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="introduction">Introduction</h1> <p>We have seen in the last post about graph signal processing and the Fourier transformation of graph data. In summary, transforming a 1D signal defined on graphs with \(n\) nodes (denoted as \(\mathbf{g} \in \mathbb{R}^n\)) requires the matrix of eigenvectors of the Laplacian matrix \(L = D - A\). Assuming that we have decomposed the Laplacian as \(L = U\Lambda U^T\), the transformation can be written as:</p> \[\hat{\mathbf{g}}[l] = {\bf u}_l^{T}{\bf g}\] <p>where \(\mathbf{u}_l\) is the \(l\)-th column in \(U\).</p> <p>Filtering operations are also defined in the frequency domain. Now following the notation from (Defferrard et al., 2016), the convolution operation between two signals \(x\) and \(y\) on graph \(G\) is defined as:</p> \[x *_{G}y = U((U^Tx)\odot(U^Ty)),\] <p>where it transforms both \(x\) and \(y\) to the frequency domain (\(U^Tx\) and \(U^T y\)), perform the convolution operation (\((U^Tx)\odot(U^Ty)\)), and return to the original domain (\(U((U^Tx)\odot(U^Ty))\)). Note that from the <a href="https://en.wikipedia.org/wiki/Convolution_theorem" rel="external nofollow noopener" target="_blank">convolution theorem</a>, element-wise multiplications in the frequency domain is the same as convolution on the original domain. In the previous post, \(U^Ty\) is analogous to the filtering operation \(h(\Lambda)\), and \(x\) to \(\mathbf{g}\) (or vice versa, actually).</p> <p>However, the most widely used form of graph convolution (GCN model from Kipf &amp; Welling) is still far from the above formulation. Between GCN and the classical graph Fourier transform, an intermediate work (Defferrard et al., 2016) has been proposed to reduce the complexity, and thus proposing a learnable graph learning model that later inspired (Defferrard et al., 2016). We will try to understand the thought behind (Defferrard et al., 2016) and perform some analysis using an experiment proposed by (Alon &amp; Yahav, 2021).</p> <h1 id="chebconv">ChebConv</h1> <p>Firstly, let us assume that we are interested in learning a filter (or graph neural network) on a given graph \(G\). Based on the description above, the straightforward approach of modeling \(h(\Lambda)\) is just making the vector \(x \in \mathbb{R}^n\) learnable. This introduces a total of \(n\) parameters (this is the non-parametric filter in ChebConv).</p> <h3 id="two-modifications-from-non-parametric-filters">Two modifications from non-parametric filters</h3> <p>The first modification of ChebConv is to reduce the number of parameters from \(n\) to \(K\) (of course, \(K &lt; n\)) by setting \(h(\Lambda)\) as a polynomial filter. That is, the filter \(h(\Lambda)\) is now expressed with respect to polynomial basis (which is literally polynomials of \(\Lambda\): \(I\), \(\Lambda\), \(\Lambda^2\), \(\cdots\)) with coefficients \(\theta_k\):</p> \[h(\Lambda) = \sum_{k=0}^{K-1}\theta_k \Lambda^k.\] <p>Putting this version of the filter to process the graph signal \(x\):</p> \[\mathbf{h}(\Lambda)x = U (\sum_{k=0}^{K-1}\theta_k \Lambda^k) U^T x = \sum_{k=0}^{K-1}\theta_k (U\Lambda^kU^T)x = \sum_{k=0}^{K-1}\theta_k L^kx\] <p>(Note that \(UU^T = I\)).</p> <p>Now the filter is \(K\)-localized, according to [2]. Intuitively, assuming the Laplacian is \(L = D-A\), notice that \(L^{K-1} = (D-A)^{K-1}\) contains \(I\) to \(A^{K-1}\), suggesting that the new signal \(\mathbf{h}(\Lambda)x\) contains information from each node to its \((K-1)\)-hop neighbor.</p> <p>The second modification is to use the Chebyshev polynomials instead of the polynomial basis. This has a number of advantages, such as the use of orthogonal basis, and more importantly, increase in efficiency since the basis can be recursively defined:</p> \[\mathbf{h}(\Lambda) = \sum_{k=0}^{K-1} \theta_k T_k(\Lambda)\] <p>(ChebConv replaces \(\Lambda\) with the normalized version \(\tilde{\Lambda}\), but we will not consider this here).</p> <h3 id="implications-of-the-chebconv-formulation">Implications of the ChebConv formulation</h3> <p>As mentioned above, the main implication of this version of graph filtering is that now the convolution affects a <strong>local neighborhood of each node</strong>, determined by the number of basis used. We will see this effect directly using the NEIGHBORSMATCH problem (Alon &amp; Yahav, 2021).</p> <h1 id="observing-the-locality-effect">Observing the locality effect</h1> <h2 id="the-neighborsmatch-problem">The NEIGHBORSMATCH problem</h2> <p>Proposed by (Alon &amp; Yahav, 2021), the NEIGHBORSMATCH problem is a task involving synthetically generated graphs. The intention of the problem is to create a task with a specific <em>problem radius</em> (i.e., the required range of interaction between a node and its neighbors for the model to solve the problem). It generates a number of synthetically generated graphs with problem radius \(r\), and a graph neural networks (GNNs) is trained to solve the task. If the GNN has less than \(r\) layers, it cannot solve the problem whatsoever.</p> <h3 id="our-modification">Our modification</h3> <p>In our case, we slightly modify the NEIGHBORSMATCH problem to a more simpler configuration. Consider a synthetically generated graph below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog3_1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog3_1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog3_1-1400.webp"></source> <img src="/assets/img/blog3_1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Visualization of a single graph with depth 4. </div> <p>[Appendix 1: Source code for the simplified NEIGHBORSMATCH] [Appendix 2: Code for generation] [Appendix 3: Code for visualizing]</p> <p>Figure 1 visualizes a single graph within the dataset generated from the code. These are some features of the graph and the dataset:</p> <ul> <li>The graph is a full binary tree, with the root node colored in red in the Figure.</li> <li>Each node is assigned with a randomply assigned integer, which serves as the node features (in implementation, the integer is encoded as a one-hot vector).</li> <li>The assigned integers of the leaf node is different with the rest of the nodes within the graph.</li> <li>The integers of the leaf node is defined as the class label of the root node.</li> <li>Consequently, the integer of the root node does not have any relationships with the actual class label.</li> </ul> <p>Similar to the original version, given a dataset consisting of such graphs, we are interested in classifying the root node ‘directly’ by using a GNN model; that is, the GNN model is to compute the class probability of the root by aggregating the neighbor information w.r.t. the root node itself.</p> <p>A direct consequence of this is that the GNN cannot solve the NEIGHBORSMATCH problem unless it has aggregated information from the leaf node to the root node.</p> <h2 id="directly-observing-the-effect-of-k">Directly observing the effect of \(K\)</h2> <p>Here, we aim to observe the receptive field generated from the ChebConv using the modified NEIGHBOURSMATCH problem above. In the following experiment, we make a GNN model using <strong>exactly one ChebConv layer</strong> with a pre-defined value of \(K\). We try to observe whether our GNN model can solve this problem with different depths of the dataset.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog3_2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog3_2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog3_2-1400.webp"></source> <img src="/assets/img/blog3_2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Performance heatmap with different depth and K values. </div> <p>[Appendix 4: Model code] [Appendix 5: Experiment code]</p> <ul> <li>We see in Figure 2 that for different values of depth for the NEIGHBORSMATCH dataset, ChebConv requires a localized filter that can at reach the leaf nodes. This is expected since the information crutial for solving the problem only exists at the feature vectors of the leaf node by design.</li> <li>Also, since the problem itself is very straightforward, the performance of the models for those that can solve is always near 1. This is despite the fact that we only used one layer of ChebConv without any non-linear actiavation functions.</li> <li>For the models that could not solve the problem, the performance degrades to a random classifier: The performance is always near \(\approx 1/(\text{num. of class})\).</li> </ul> <h2 id="chance-of-redemption-stacking-layers">Chance of redemption: Stacking layers</h2> <p>For ChebConv layers that does not have enough receptive field, we can still make the models solve the problem with a simple modification: <strong>stacking the layers</strong>. Since each convolutions aggregate information from the neighbors from the receptive field, stacking multiple convolutions will make the information travel more. This design choice is also highlighted in the next paper that we will cover (GCN).</p> <p>To see this effect, we will build several models using ChebConv layers, each with receptive field of \(K=2\). However, the task will be generated with varying depth values from 1 to 6 . In the first experiment (where we restricted ourselves to a one layer model), the model is bound to fail for depth greater than 1. In this experiment, we will attempt to stack layers for all depth values until the model can finally solve the problem.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog3_3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog3_3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog3_3-1400.webp"></source> <img src="/assets/img/blog3_3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Performance heatmap with different depths and the number of layers (K=2). </div> <p>[Appendix 6: Model code] [Appendix 7: Experiment log]</p> <p>Here, we can see that stacking enough layers, the model will eventually be able to solve the task. Also notice that for the cases where the model fails, the performance is roughly \(1/(\text{num. of classes})\), indicating that the model is basically a random classifier. Let’s look at an another case where we stack ChebConv layers with \(K=3\):</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog3_4-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog3_4-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog3_4-1400.webp"></source> <img src="/assets/img/blog3_4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Performance heatmap with different depths and number of layers (K=3). </div> <p>[Appendix 8: Experiment log]</p> <p>As expected, the depth that the model can solve now increases twice as fast per layer compared to the case when \(K=2\). Note that there are no benefits of stacking layers for \(K=1\) for solving NEIGHBORSMATCH as it only learns filters of itself (remember the first term of the Chebyshev polynomial is the identity matrix \(I\)) and does not take neighbor nodes into consideration.</p> <h1 id="conclusions">Conclusions</h1> <p>We have observed the main idea of ChebConv, along with its interpretation in terms of receptive field. Running various experiments on the NEIGHBORSMATCH problem, we were able to directly observe the effect of \(K\) on the solvability of the task, which is designed to be solved with a model that can cover the task’s problem radius.</p> <h1 id="appendix">Appendix</h1> <h2 id="appendix-1">Appendix 1</h2> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch_geometric</span>
<span class="kn">from</span> <span class="n">torch_geometric.data</span> <span class="kn">import</span> <span class="n">Data</span>
<span class="kn">from</span> <span class="n">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">random</span>

<span class="sh">"""</span><span class="s">
Based on the original implementation of the NEIGHBORSMATCH dataset.
Original implementation: https://github.com/tech-srl/bottleneck
Alon &amp; Yahav, </span><span class="sh">"</span><span class="s">ON THE BOTTLENECK OF GRAPH NEURAL NETWORKS AND ITS PRACTICAL IMPLICATIONS</span><span class="sh">"</span><span class="s">, ICLR 2021
</span><span class="sh">"""</span>

<span class="k">class</span> <span class="nc">TreeDataset</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">num_of_class</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">7</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">TreeDataset</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">depth</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">edges</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">leaf_indices</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_create_blank_tree</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">cross_entropy</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_of_class</span> <span class="o">=</span> <span class="n">num_of_class</span>
        <span class="n">self</span><span class="p">.</span><span class="n">feature_constructor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_of_class</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_child_edges</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">cur_node</span><span class="p">,</span> <span class="n">max_node</span><span class="p">):</span>
        <span class="n">edges</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">leaf_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">stack</span> <span class="o">=</span> <span class="p">[(</span><span class="n">cur_node</span><span class="p">,</span> <span class="n">max_node</span><span class="p">)]</span>
        <span class="k">while</span> <span class="n">stack</span><span class="p">:</span>
            <span class="n">cur_node</span><span class="p">,</span> <span class="n">max_node</span> <span class="o">=</span> <span class="n">stack</span><span class="p">.</span><span class="nf">pop</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">cur_node</span> <span class="o">==</span> <span class="n">max_node</span><span class="p">:</span>
                <span class="n">leaf_indices</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">cur_node</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="n">left_child</span> <span class="o">=</span> <span class="n">cur_node</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">right_child</span> <span class="o">=</span> <span class="n">cur_node</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="p">((</span><span class="n">max_node</span> <span class="o">-</span> <span class="n">cur_node</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">edges</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="p">[</span><span class="n">left_child</span><span class="p">,</span> <span class="n">cur_node</span><span class="p">],</span>
                    <span class="p">[</span><span class="n">right_child</span><span class="p">,</span> <span class="n">cur_node</span><span class="p">],</span>
                    <span class="p">[</span><span class="n">cur_node</span><span class="p">,</span> <span class="n">left_child</span><span class="p">],</span>
                    <span class="p">[</span><span class="n">cur_node</span><span class="p">,</span> <span class="n">right_child</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">stack</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">right_child</span><span class="p">,</span> <span class="n">max_node</span><span class="p">))</span>
            <span class="n">stack</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">left_child</span><span class="p">,</span> <span class="n">right_child</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">edges</span><span class="p">,</span> <span class="n">leaf_indices</span>

    <span class="k">def</span> <span class="nf">_create_blank_tree</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">max_node_id</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>
        <span class="n">edges</span><span class="p">,</span> <span class="n">leaf_indices</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">add_child_edges</span><span class="p">(</span><span class="n">cur_node</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_node</span><span class="o">=</span><span class="n">max_node_id</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">max_node_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">leaf_indices</span>

    <span class="k">def</span> <span class="nf">create_blank_tree</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">add_self_loops</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="n">edge_index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">edges</span><span class="p">).</span><span class="nf">t</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">add_self_loops</span><span class="p">:</span>
            <span class="n">edge_index</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch_geometric</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">add_remaining_self_loops</span><span class="p">(</span>
                <span class="n">edge_index</span><span class="o">=</span><span class="n">edge_index</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">edge_index</span>

    <span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">train_fraction</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20000</span><span class="p">):</span>
        <span class="n">data_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">):</span>
            <span class="n">edge_index</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">create_blank_tree</span><span class="p">(</span><span class="n">add_self_loops</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="n">nodes</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">get_nodes_features_and_labels</span><span class="p">()</span>
            <span class="n">data_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
                <span class="nc">Data</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">nodes</span><span class="p">,</span> <span class="n">edge_index</span><span class="o">=</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span>
            <span class="n">data_list</span><span class="p">,</span>
            <span class="n">train_size</span><span class="o">=</span><span class="n">train_fraction</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">stratify</span><span class="o">=</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">y</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_list</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span>

    <span class="k">def</span> <span class="nf">get_nodes_features_and_labels</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">num_of_class</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">feature_ind</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">LongTensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">num_nodes</span><span class="p">)</span>
        <span class="n">feature_ind</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">leaf_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">label</span>

        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">feature_constructor</span><span class="p">[</span><span class="n">feature_ind</span><span class="p">]),</span> <span class="n">label</span></code></pre></figure> <h2 id="appendix-2">Appendix 2</h2> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="sh">"""</span><span class="s">
Code for generating the dataset
Modify the depth, num_of_class, and train_fraction for your need
</span><span class="sh">"""</span>
<span class="n">tree</span> <span class="o">=</span> <span class="nc">TreeDataset</span><span class="p">(</span><span class="n">depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">num_of_class</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">tree</span><span class="p">.</span><span class="nf">generate_data</span><span class="p">(</span><span class="n">train_fraction</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span></code></pre></figure> <h2 id="appendix-3">Appendix 3</h2> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="sh">"""</span><span class="s">
Code for visualizing one of the dataset.
</span><span class="sh">"""</span>
<span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="kn">from</span> <span class="n">torch_geometric.utils</span> <span class="kn">import</span> <span class="n">to_networkx</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">ind</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># Index of the graph to visulaize
</span><span class="n">tree_nx</span> <span class="o">=</span> <span class="nf">to_networkx</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">ind</span><span class="p">],</span> <span class="n">to_undirected</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># Need networkx for this
# Node features
</span><span class="n">labeldict</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">ind</span><span class="p">].</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]).</span><span class="nf">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">ind</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])}</span>
<span class="n">color</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="sh">'</span><span class="s">g</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">ind</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Only the root node is colored as red
</span>
<span class="c1"># Draw via networkx
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">dpi</span> <span class="o">=</span> <span class="mi">120</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Example (Class label </span><span class="si">{</span><span class="n">X_train</span><span class="p">[</span><span class="n">ind</span><span class="p">].</span><span class="n">y</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span><span class="p">)</span>
<span class="n">nx</span><span class="p">.</span><span class="nf">draw</span><span class="p">(</span><span class="n">tree_nx</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">labeldict</span><span class="p">,</span> <span class="n">with_labels</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">node_color</span> <span class="o">=</span> <span class="n">color</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span></code></pre></figure> <h2 id="appendix-4">Appendix 4</h2> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">ChebConv</span>


<span class="k">class</span> <span class="nc">GNN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">self</span><span class="p">.</span><span class="n">convs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
                <span class="nc">ChebConv</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">convs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
            <span class="nc">ChebConv</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="nf">unique</span><span class="p">()))</span>
        <span class="k">for</span> <span class="n">conv</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">convs</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nf">conv</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="o">=</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">root_index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">LongTensor</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="n">num_nodes</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="n">root_index</span><span class="p">]</span></code></pre></figure> <h2 id="appendix-5">Appendix 5</h2> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">ChebConv</span>
<span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="n">itertools</span> <span class="kn">import</span> <span class="n">product</span>


<span class="k">class</span> <span class="nc">Experiment</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">num_of_class</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">K</span>
        <span class="n">self</span><span class="p">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">depth</span>
        <span class="n">self</span><span class="p">.</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">test_loader</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">prepare_dataset</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">num_of_class</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="nc">GNN</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span>
            <span class="n">out_channels</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span>
            <span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
        <span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">8</span>

    <span class="k">def</span> <span class="nf">make_data</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">num_of_class</span><span class="p">):</span>
        <span class="n">tree</span> <span class="o">=</span> <span class="nc">TreeDataset</span><span class="p">(</span><span class="n">depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span> <span class="n">num_of_class</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">tree</span><span class="p">.</span><span class="n">num_of_class</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">tree</span><span class="p">.</span><span class="n">num_of_class</span>
        <span class="k">return</span> <span class="n">tree</span><span class="p">.</span><span class="nf">generate_data</span><span class="p">(</span><span class="n">train_fraction</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">prepare_dataset</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">num_of_class</span><span class="p">):</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">make_data</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">num_of_class</span><span class="p">)</span>
        <span class="n">train_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">test_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">train_loader</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">cross_entropy</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>
            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="nf">float</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="o">*</span> <span class="n">data</span><span class="p">.</span><span class="n">num_graphs</span>
        <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train_loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="nd">@torch.no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">loader</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="n">total_correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">),</span>
                <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">total_correct</span> <span class="o">+=</span> <span class="nf">int</span><span class="p">((</span><span class="n">pred</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">).</span><span class="nf">sum</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">total_correct</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">run_experiment</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
            <span class="n">train_acc</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">test</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train_loader</span><span class="p">)</span>
            <span class="n">test_acc</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">test</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">test_loader</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">test_acc</span>

<span class="sh">"""</span><span class="s">
Run the actual experiment
</span><span class="sh">"""</span>
<span class="n">performance_heatmap</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

<span class="k">for</span> <span class="n">K</span><span class="p">,</span> <span class="n">depth</span> <span class="ow">in</span> <span class="nf">product</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">)):</span>
    <span class="n">perf</span> <span class="o">=</span> <span class="nc">Experiment</span><span class="p">(</span><span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span> <span class="n">num_of_class</span><span class="o">=</span><span class="mi">7</span><span class="p">).</span><span class="nf">run_experiment</span><span class="p">()</span>
    <span class="n">performance_heatmap</span><span class="p">[</span><span class="n">K</span><span class="p">][</span><span class="n">depth</span><span class="p">]</span> <span class="o">=</span> <span class="n">perf</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">K: </span><span class="si">{</span><span class="n">K</span><span class="si">}</span><span class="s">, depth: </span><span class="si">{</span><span class="n">depth</span><span class="si">}</span><span class="s">, performance: </span><span class="si">{</span><span class="n">perf</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>


<span class="o">&gt;&gt;&gt;</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.144</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.1445</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14725</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14325</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14725</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14875</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14425</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.147</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.1425</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.1455</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.1475</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14625</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14825</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.1445</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14525</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">K</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span></code></pre></figure> <h2 id="appendix-6">Appendix 6</h2> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">GNN_new</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_layers</span> <span class="o">=</span>  <span class="n">num_layers</span>
        <span class="n">self</span><span class="p">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="n">convs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">ChebConv</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="n">convs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">ChebConv</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="nf">unique</span><span class="p">()))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">convs</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">root_index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">LongTensor</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="n">num_nodes</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="n">root_index</span><span class="p">,</span> <span class="p">:]</span></code></pre></figure> <h2 id="appendix-7">Appendix 7</h2> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">Num_layers</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.146</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14475</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14725</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14525</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.1445</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14525</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14525</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14425</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.1465</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.1455</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.145</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.1445</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.1485</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14475</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14425</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span></code></pre></figure> <h2 id="appendix-8">Appendix 8</h2> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">Num_layers</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.145</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14575</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14675</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.14625</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.1445</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">0.145</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="n">Num_layers</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">1.0</span></code></pre></figure> </div> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div> <div id="Alon2021neighborsmatch" class="col-sm-8"> <div class="title">On the Bottleneck of Graph Neural Networks and its Practical Implications</div> <div class="author"> Uri Alon, and Eran Yahav</div> <div class="periodical"> <em>In ICLR</em>, May 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openreview.net/forum?id=i80OPhOCVH2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li></ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div> <div id="Kipf2017gcn" class="col-sm-8"> <div class="title">Semi-Supervised Classification with Graph Convolutional Networks</div> <div class="author"> Thomas N. Kipf, and Max Welling</div> <div class="periodical"> <em>In ICLR</em>, Apr 2017 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openreview.net/forum?id=SJU4ayYgl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li></ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div id="Defferrard2016chebconv" class="col-sm-8"> <div class="title">Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</div> <div class="author"> Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst</div> <div class="periodical"> <em>In NeurIPS</em>, Dec 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="https://proceedings.neurips.cc/paper/2016/hash/04df4d434d481c5bb723be1b6df1ee65-Abstract.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li></ol> <h2 class="bibliography">2013</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="Shuman2013graphspectral" class="col-sm-8"> <div class="title">The Emerging Field of Signal Processing on Graphs: Extending High-Dimensional Data Analysis to Networks and Other Irregular Domains</div> <div class="author"> David I. Shuman, Sunil K. Narang, Pascal Frossard, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Antonio Ortega, Pierre Vandergheynst' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>IEEE Signal Process. Mag.</em>, Dec 2013 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/MSP.2012.2235192" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li></ol> </div> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/Cora_spectral/">Dissecting Cora in the Spectral Domain</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/Revisiting_SSL/">Revisiting Modern Benchmarks for Semi-suparvised Node Classification using Classical Methods</a> </li> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"jordan7186/jordan7186.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Yong-Min Shin. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>