---
layout: about
title: About
permalink: /
subtitle: <a href='https://www.linkedin.com/in/yongminshin/'>LinkedIn,</a><a href='https://twitter.com/YongminWavyShin'>Twitter,</a><a href='https://github.com/jordan7186'>Github</a>

profile:
  align: right
  image: profile.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>jordan3414@yonsei.ac.kr</p>

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
latest_posts: true  # includes a list of the newest posts
social: false # includes social icons at the bottom of the page
---

Hello! I am a Ph.D candidate in [MIDaS Lab](https://sites.google.com/site/midasyonsei) led by *Prof. Won-Yong Shin*, [Dept. Computer Science & Engineering](https://cse.yonsei.ac.kr/cse/index.do) in Yonsei University, South Korea. Before joining MIDaS, I graduated from Yonsei University in Feb. 2019 as a physics major. 

My primary interest is to find elegant and simple solutions to interesting and important problems on **graph data** and **graph neural networks (GNNs).** More specifically, my main research topics have been focused primarily on…

- **Explainability** in graph neural networks
- **Efficient** graph learning

And my current research focuses on...

- Exploiting explanations from graph learning modules to improve the underlying data
- Diving into the evaluation protocols for explainability, especially using attention weights
- Fusion of graph neural networks with large language models

I also have research experiences in…

- Time-series with INR
- Graph representation learning
- Explainable healthcare
- Recommendation systems

...which are published in conferences like AAAI, IJCAI, SIGIR, LoG, and journals like PAMI, PlosOne, and so on.


I am always interested in reading about for other research fields, for example in...
- Mechanistic Interpretability: I personally think that this is the future of XAI research. I just started to pick up some papers on this topic and I am trying to understand the concept of mechanistic interpretability. As a means to learn more about this topic, I am currently translating several important articles on mechanistic interpretability into Korean. **Check out this [Gitbook](https://lesskorrect.gitbook.io/mechanistic-interpretability) if you are interested!**
- Causal Inference: With the help of Brady Neal's [Introduction to Causal Inference](https://www.bradyneal.com/causal-inference-course), I am trying to understand the concept of causality to understand how it can impact the explainability of machine learning models.

I am always open to new ideas and collaborations, so feel free to reach out to me!

Here is my formal <a href="https://drive.google.com/file/d/1UhefwaijAm7FC312RY2UYLxnRH0jNrqY/view?usp=sharing">CV</a> :)

And I also have a <a href="https://yongminshin.thesimple.ink/">personal blog</a>. Check it out!

