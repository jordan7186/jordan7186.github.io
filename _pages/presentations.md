---
layout: page
permalink: /presentations/
title: Presentations
description: These are the selected presentation slides that I have used in internal reading groups, workshops, and conferences.
nav: true
nav_order: 3
---

## External presentations

## Seminar series @ GIST
This is a series of seminars that I gave at Gwangju Institute of Science and Technology (GIST) as a guest speaker from March ~ June 2024. The seminar series was about the basics of graph neural networks, several fundamental concepts, and applications of GNNs.

(Slides TBA)

#### PAGE: Prototype-Based Model-Level Explanations for Graph Neural Networks
This presentation slides were submitted as an official supplementary material after being accepted as the best academic paper at the Graduate School of Yonsei University.

Slide: [PAGE: Prototype-Based Model-Level Explanations for Graph Neural Networks](/assets/pdf/Presentation_PAGE.pdf)

Also, this is the poster that I presented for the short version, accepted at AAAI 2022.

<div class="embed-container">
  <iframe src="https://drive.google.com/file/d/1G5zppNVts4XQ8LfuPyp-KqbgtlWlY7L1/preview" width="360" height="480"></iframe>
</div>

#### Edgeless-GNN: Unsupervised Inductive Edgeless Network Embedding
This presentation was given during the 28th Samsung HumanTech award, which eventually led to the award of the bronze prize.

<div class="embed-container">
  <iframe src="https://drive.google.com/file/d/1amqs6noFUlW0eYo8EuipCMdKMRHWmuki/preview" width="640" height="360"></iframe>
</div>


## Internal presentations

#### Causal learning

This was a two-part presentation where I introduced the basics of causal learning in an internal seminar at my lab, which I got a LOT of help from ["Introduction to Causal Inference" by Brady Neal](https://www.bradyneal.com/causal-inference-course). Thank you!!

<div class="embed-container">
  <iframe src="https://drive.google.com/file/d/1CUNenpkm3Jxxw0RPjqHTtCXu1phce08W/preview" width="640" height="360"></iframe>
</div>

<div class="embed-container">
  <iframe src="https://drive.google.com/file/d/1OCHw7_Mbm3qUFPxz9fIdxTI8KILV3WAv/preview" width="640" height="360"></iframe>
</div>

#### Self-supervised learning

- [Introduction to SimCLR](https://drive.google.com/file/d/1aafQ5f6egM1TGsZXehRzzp1Z6coHRhqY/view?usp=sharing): This was a presentation made when I was interested in understanding the SimCLR framework.

<div class="embed-container">
  <iframe src="https://drive.google.com/file/d/1aafQ5f6egM1TGsZXehRzzp1Z6coHRhqY/preview" width="640" height="360"></iframe>
</div>


#### Knowledge distillation

- [Towards understanding knowledge distillation](https://drive.google.com/file/d/1Nf40Y0ZuSJVzOlObBczgkJ0ksqeHzvg-/view?usp=sharing): This was a presentation made when I was interested in understanding knowledge distillation, which I eventually applied to my research on efficient graph learning.

<div class="embed-container">
  <iframe src="https://drive.google.com/file/d/1Nf40Y0ZuSJVzOlObBczgkJ0ksqeHzvg-/preview" width="640" height="360"></iframe>
</div>

#### Physics-informed machine learning (PIML)

- A review of the paper: [Vector Neurons: A General Framework for SO(3)-Equivariant Networks](https://drive.google.com/file/d/1BeaBhggwPEDEFIDJLQqg8mz_CN9tQe-p/view?usp=sharing) by Dent et al. This was a presentation made when I was interested in understanding the physics-informed machine learning landscape.

<div class="embed-container">
  <iframe src="https://drive.google.com/file/d/1BeaBhggwPEDEFIDJLQqg8mz_CN9tQe-p/preview" width="640" height="360"></iframe>
</div>


#### Unsupervised disentanglement

- A review of the paper: [Challenging common assumptions in the unsupervised learning of disentangled representations](https://drive.google.com/file/d/1HS-CQ_xUj0D8hbzmQORz0K7_B8ptG6gj/view?usp=sharing) by Locatello et al.

<div class="embed-container">
  <iframe src="https://drive.google.com/file/d/1HS-CQ_xUj0D8hbzmQORz0K7_B8ptG6gj/preview" width="640" height="360"></iframe>
</div>
